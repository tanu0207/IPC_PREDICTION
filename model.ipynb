{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f599ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in c:\\python311\\lib\\site-packages (3.1.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_hub as hub\n",
    "#Importing Universal sentence encoder\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1b8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "def IPC_Self_learning_Model(text):\n",
    "  train_data=pd.read_excel(\"ipc_data_1.xlsx\")\n",
    "  X = train_data[\"Offence\"].to_list()\n",
    "  X = np.array(X)\n",
    "  train_data_1= train_data['Section']\n",
    "  train_data_1 = train_data_1.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "  multilabel = MultiLabelBinarizer()\n",
    "  y = multilabel.fit_transform(train_data_1)\n",
    "\n",
    "\n",
    "  # Define feature extractor model using TF Hub layer\n",
    "  inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "  pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
    "  x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
    "  # Note: you could add more layers here if you wanted to\n",
    "  outputs = layers.Dense(len(multilabel.classes_), activation=\"softmax\")(x) # create the output layer\n",
    "  model_1 = tf.keras.Model(inputs=inputs,\n",
    "                          outputs=outputs)\n",
    "  \n",
    "\n",
    "\n",
    "  # Compile the model\n",
    "  model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "  model_1.fit(X,  y,\n",
    "               epochs=30,\n",
    "                verbose=0)\n",
    "  \n",
    "  text = np.array([text])\n",
    "  model_1_pred_probs = model_1.predict(text)\n",
    "  n=2\n",
    "  indices_2 = (-model_1_pred_probs).argsort()[:n]\n",
    "  q=[]\n",
    "  for r in range(0,4):\n",
    "    q.append(multilabel.classes_[indices_2[0,r]])\n",
    "  \n",
    "\n",
    "  return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52d8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "offence_ =\"Murder\" #Enter any offence u want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ae07f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 363ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_ipc = IPC_Self_learning_Model(offence_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bed1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_excel(\"ipc_data_1.xlsx\")\n",
    "Off = train_data[\"Offence\"]\n",
    "punish = train_data[\"Punishment\"]\n",
    "train_data_1= train_data['Section']\n",
    "train_data_1 = train_data_1.apply(lambda x: ast.literal_eval(x))\n",
    "Sec_1= train_data_1\n",
    "\n",
    "data = {}  # Initialize data as an empty dictionary\n",
    "\n",
    "for x in range(0, 382):\n",
    "    data[Sec_1[x][0]] = [Off[x], punish[x]]\n",
    "\n",
    "def data_retrival(code):\n",
    "    detail = []\n",
    "    punishment = []\n",
    "    for i in code:  \n",
    "        detail.append(data[i][0])\n",
    "        punishment.append(data[i][1])\n",
    "    for j in range(len(code)):\n",
    "        print(f\"{code[j]}\\n Detail:{detail[j]}\\n Punishment:{punishment[j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae42f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 IPC\n",
      " Detail:Murder\n",
      " Punishment:Death, or imprisonmentfor life, and fine\n",
      "396 IPC\n",
      " Detail:Murder in dacoity\n",
      " Punishment:Death, imprisonment for life, or rigorous imprisonment for 10 years and fine\n",
      "307 IPC\n",
      " Detail:Attempt to murder\n",
      " Punishment:Imprisonment for life, or imprisonment for 10 years and fine.\n",
      "308 IPC\n",
      " Detail:Attempt to commit culpable homicide.\n",
      " Punishment:Imprisonment for 3 years, or fine, or both.\n"
     ]
    }
   ],
   "source": [
    "data_retrival(pred_ipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0edb5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Function to handle button click event\n",
    "def show_result():\n",
    "    offence = offence_entry.get()\n",
    "    pred_ipc = IPC_Self_learning_Model(offence)\n",
    "    data_retrival(pred_ipc)\n",
    "\n",
    "# Create tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"IPC Offence Predictor\")\n",
    "root.geometry(\"400x300\")  # Set window dimensions\n",
    "\n",
    "# Style for the tkinter elements\n",
    "style = ttk.Style()\n",
    "style.configure(\"TButton\", padding=10, font=(\"Arial\", 12))\n",
    "style.configure(\"TLabel\", padding=10, font=(\"Arial\", 12))\n",
    "\n",
    "# Label and entry for entering offence\n",
    "offence_label = ttk.Label(root, text=\"Enter Offence:\")\n",
    "offence_label.pack(pady=10)  # Add padding around the label\n",
    "offence_entry = ttk.Entry(root, font=(\"Arial\", 12))\n",
    "offence_entry.pack(pady=10)  # Add padding around the entry field\n",
    "\n",
    "# Button to predict IPC sections\n",
    "predict_button = ttk.Button(root, text=\"Predict IPC Sections\", command=show_result)\n",
    "predict_button.pack(pady=20)  # Add padding around the button\n",
    "\n",
    "# Frame to display results\n",
    "result_frame = ttk.Frame(root)\n",
    "result_frame.pack(padx=20, pady=10)  # Add padding around the frame\n",
    "result_label = ttk.Label(result_frame, wraplength=350, font=(\"Arial\", 11))\n",
    "result_label.pack()\n",
    "\n",
    "# Function to display results\n",
    "def data_retrival(code):\n",
    "    result_label.config(text=\"\")\n",
    "    detail = []\n",
    "    punishment = []\n",
    "    for i in code:\n",
    "        detail.append(data[i][0])\n",
    "        punishment.append(data[i][1])\n",
    "    for j in range(len(code)):\n",
    "        result_label.config(text=result_label.cget(\"text\") + f\"{code[j]}\\n Detail: {detail[j]}\\n Punishment: {punishment[j]}\\n\\n\")\n",
    "\n",
    "# Run the tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2365bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.9817232489585876\n",
      "1/1 [==============================] - 0s 297ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_hub as hub\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Importing Universal sentence encoder\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")\n",
    "\n",
    "def IPC_Self_learning_Model(text):\n",
    "    train_data = pd.read_excel(\"ipc_data_1.xlsx\")\n",
    "    X = train_data[\"Offence\"].to_list()\n",
    "    X = np.array(X)\n",
    "    train_data_1 = train_data['Section']\n",
    "    train_data_1 = train_data_1.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    multilabel = MultiLabelBinarizer()\n",
    "    y = multilabel.fit_transform(train_data_1)\n",
    "\n",
    "    # Define feature extractor model using TF Hub layer\n",
    "    inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "    pretrained_embedding = tf_hub_embedding_layer(inputs)\n",
    "    x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
    "    outputs = layers.Dense(len(multilabel.classes_), activation=\"softmax\")(x)\n",
    "    model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    # Fit the model and store the training history\n",
    "    history = model_1.fit(X, y, epochs=30, verbose=0)\n",
    "\n",
    "    # Print the accuracy\n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    print(f\"Final Training Accuracy: {accuracy}\")\n",
    "\n",
    "    text = np.array([text])\n",
    "    model_1_pred_probs = model_1.predict(text)\n",
    "    n = 2\n",
    "    indices_2 = (-model_1_pred_probs).argsort()[:n]\n",
    "    q = []\n",
    "    for r in range(0, 4):\n",
    "        q.append(multilabel.classes_[indices_2[0, r]])\n",
    "\n",
    "    return q\n",
    "\n",
    "def data_retrival(code):\n",
    "    result_text.config(state=tk.NORMAL)\n",
    "    result_text.delete(1.0, tk.END)\n",
    "    detail = []\n",
    "    punishment = []\n",
    "    for i in code:\n",
    "        detail.append(data[i][0])\n",
    "        punishment.append(data[i][1])\n",
    "    for j in range(len(code)):\n",
    "        result_text.insert(tk.END, f\"{code[j]}\\n Detail: {detail[j]}\\n Punishment: {punishment[j]}\\n\\n\")\n",
    "    result_text.config(state=tk.DISABLED)\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_excel(\"ipc_data_1.xlsx\")\n",
    "Off = train_data[\"Offence\"]\n",
    "punish = train_data[\"Punishment\"]\n",
    "train_data_1 = train_data['Section']\n",
    "train_data_1 = train_data_1.apply(lambda x: ast.literal_eval(x))\n",
    "Sec_1 = train_data_1\n",
    "\n",
    "# Initialize data as an empty dictionary\n",
    "data = {}\n",
    "for x in range(0, 382):\n",
    "    data[Sec_1[x][0]] = [Off[x], punish[x]]\n",
    "\n",
    "# Create tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"IPC Offence Predictor\")\n",
    "root.geometry(\"400x400\")  # Set window dimensions\n",
    "\n",
    "# Style for the tkinter elements\n",
    "style = ttk.Style()\n",
    "style.configure(\"TButton\", padding=10, font=(\"Arial\", 12))\n",
    "style.configure(\"TLabel\", padding=10, font=(\"Arial\", 12))\n",
    "\n",
    "# Label and entry for entering offence\n",
    "offence_label = ttk.Label(root, text=\"Enter Offence:\")\n",
    "offence_label.pack(pady=10)\n",
    "offence_entry = ttk.Entry(root, font=(\"Arial\", 12))\n",
    "offence_entry.pack(pady=10)\n",
    "\n",
    "# Button to predict IPC sections\n",
    "predict_button = ttk.Button(root, text=\"Predict IPC Sections\", command=lambda: show_result())\n",
    "predict_button.pack(pady=20)\n",
    "\n",
    "# Frame to display results using Text widget\n",
    "result_frame = ttk.Frame(root)\n",
    "result_frame.pack(padx=20, pady=10)\n",
    "\n",
    "result_text = tk.Text(result_frame, wrap=tk.WORD, height=10, width=40, font=(\"Arial\", 11))\n",
    "result_text.pack()\n",
    "\n",
    "def show_result():\n",
    "    offence = offence_entry.get()\n",
    "    pred_ipc = IPC_Self_learning_Model(offence)\n",
    "    data_retrival(pred_ipc)\n",
    "\n",
    "# Run the tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71f076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
